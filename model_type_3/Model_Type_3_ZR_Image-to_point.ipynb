{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Type 2: Z-R point model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import SGD\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Local application/library specific imports\n",
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "base_path = 'C:/Users/Henri/Emilie/Thesis'\n",
    "sys.path.append(base_path + '/code')\n",
    "import project_functions as pf\n",
    "importlib.reload(pf) # Reloading the local module \n",
    "\n",
    "# Reloading the local module \n",
    "importlib.reload(pf)\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available. Using CPU.\")\n",
    "    \n",
    "# Function to set seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "    \n",
    "base_path = 'C:/Users/Henri/Emilie/Thesis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZR_dataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir='C:/Users/Henri/Emilie/Thesis/data/images/train', num_samples=100):\n",
    "        self.df_full = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Convert 'timestamp' column to datetime\n",
    "        self.df_full['timestamp'] = pd.to_datetime(self.df_full['timestamp'])\n",
    "        \n",
    "        # Filter the rows where the minute value is a multiple of 10\n",
    "        self.df_full = self.df_full[self.df_full['timestamp'].dt.minute % 10 == 0]\n",
    "        \n",
    "        # Filter out rows with Z = 0, R = null, or Z = null\n",
    "        self.df_filtered = self.df_full[(self.df_full['R'] != 0) & (self.df_full['Z'] != 0) & ~self.df_full['R'].isnull() & ~self.df_full['Z'].isnull()]\n",
    "\n",
    "        # Sample indices without replacement from the filtered DataFrame\n",
    "        #if len(self.df_filtered) > num_samples:\n",
    "        #    self.sampled_indices = np.random.choice(self.df_filtered.index, size=num_samples, replace=False)\n",
    "        #else:\n",
    "        self.sampled_indices = self.df_filtered.index\n",
    "\n",
    "        # Create a sampled DataFrame based on the sampled indices\n",
    "        self.df_sampled = self.df_filtered.loc[self.sampled_indices].reset_index(drop=True)\n",
    "\n",
    "        # No sampling, use all data\n",
    "        self.df_sampled = self.df_filtered.reset_index(drop=True)\n",
    "        \n",
    "        # Convert relevant columns to float and to a NumPy array for faster access\n",
    "        self.features = self.df_sampled[['radar_norm', 'dist_coast', 'dist_radar', 'topo', 'toy_sin', 'toy_cos', 'tod_sin', 'tod_cos']].astype(float).values\n",
    "        self.R = self.df_sampled['R'].astype(float).values\n",
    "        self.Z = self.df_sampled['Z'].astype(float).values\n",
    "        self.dBZ = self.df_sampled['dBZ'].astype(float).values\n",
    "        self.image_paths = self.df_sampled['cropped_radar_image_path'].values  # Load image paths\n",
    "        self.station_ids = self.df_sampled['stationId'].values  # Load station IDs\n",
    "        self.image_dir = image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZR_dataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir='C:/Users/Henri/Emilie/Thesis/data/images/train', num_samples=100):\n",
    "        self.df_full = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Convert 'timestamp' column to datetime\n",
    "        self.df_full['timestamp'] = pd.to_datetime(self.df_full['timestamp'])\n",
    "        \n",
    "        # Filter the rows where the minute value is a multiple of 10\n",
    "        self.df_full = self.df_full[self.df_full['timestamp'].dt.minute % 10 == 0]\n",
    "        \n",
    "        # Filter out rows with Z = 0, R = null, or Z = null\n",
    "        self.df_filtered = self.df_full[(self.df_full['R'] != 0) & (self.df_full['Z'] != 0) & ~self.df_full['R'].isnull() & ~self.df_full['Z'].isnull()]\n",
    "\n",
    "        # Sample indices without replacement from the filtered DataFrame\n",
    "        #if len(self.df_filtered) > num_samples:\n",
    "        #    self.sampled_indices = np.random.choice(self.df_filtered.index, size=num_samples, replace=False)\n",
    "        #else:\n",
    "        self.sampled_indices = self.df_filtered.index\n",
    "\n",
    "        # Create a sampled DataFrame based on the sampled indices\n",
    "        self.df_sampled = self.df_filtered.loc[self.sampled_indices].reset_index(drop=True)\n",
    "\n",
    "        # No sampling, use all data\n",
    "        self.df_sampled = self.df_filtered.reset_index(drop=True)\n",
    "        \n",
    "        # Convert relevant columns to float and to a NumPy array for faster access\n",
    "        self.features = self.df_sampled[['radar_norm', 'dist_coast', 'dist_radar', 'topo', 'toy_sin', 'toy_cos', 'tod_sin', 'tod_cos']].astype(float).values\n",
    "        self.R = self.df_sampled['R'].astype(float).values\n",
    "        self.Z = self.df_sampled['Z'].astype(float).values\n",
    "        self.dBZ = self.df_sampled['dBZ'].astype(float).values\n",
    "        self.image_paths = self.df_sampled['cropped_radar_image_path'].values  # Load image paths\n",
    "        self.station_ids = self.df_sampled['stationId'].values  # Load station IDs\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.R)  # Return the length of the sampled DataFrame\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Directly access the pre-converted numpy arrays\n",
    "        x = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        R = torch.tensor(self.R[idx], dtype=torch.float)\n",
    "        Z = torch.tensor(self.Z[idx], dtype=torch.float)\n",
    "        dBZ = torch.tensor(self.dBZ[idx], dtype=torch.float)\n",
    "        \n",
    "        # Load the current image and its timestamp\n",
    "        current_image_path = self.image_paths[idx]\n",
    "        current_image = Image.open(current_image_path)\n",
    "        current_image = ToTensor()(current_image)  # Converts the image to a PyTorch tensor and normalizes to [0, 1]\n",
    "\n",
    "        # Parse the timestamp from the image filename\n",
    "        timestamp_str = os.path.basename(current_image_path).split('_')[1] + '_' + os.path.basename(current_image_path).split('_')[2]\n",
    "        try:\n",
    "            timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d_%H-%M-%S')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d')\n",
    "            except ValueError as e:\n",
    "                raise ValueError(f\"Unexpected timestamp format in filename: {current_image_path}\") from e\n",
    "        \n",
    "        # Get the station ID\n",
    "        station_id = self.station_ids[idx]\n",
    "\n",
    "        # Define time offsets including the current timestamp\n",
    "        time_offsets = [\n",
    "            timedelta(minutes=0),\n",
    "            timedelta(minutes=10),\n",
    "            timedelta(minutes=20),\n",
    "            timedelta(minutes=30),\n",
    "            timedelta(minutes=40),\n",
    "            timedelta(minutes=50),\n",
    "            timedelta(minutes=60)\n",
    "        ]\n",
    "\n",
    "        # Initialize a list to hold images and image paths\n",
    "        images = []\n",
    "        image_paths = []\n",
    "\n",
    "        for offset in time_offsets:\n",
    "            past_timestamp = timestamp - offset\n",
    "            past_image_path = self.get_image_path(past_timestamp, station_id)\n",
    "            #print(f'Loading image from: {past_image_path}')  # Debug print to check image paths\n",
    "            image_paths.append(past_image_path)\n",
    "            if past_image_path and os.path.exists(past_image_path):\n",
    "                past_image = Image.open(past_image_path)\n",
    "                past_image = ToTensor()(past_image)\n",
    "                images.append(past_image)\n",
    "            else:\n",
    "                #print(f'Image not found, using blank image for: {past_image_path}')  # Debug print for missing images\n",
    "                images.append(torch.zeros_like(current_image))  # Use a blank image if the past image is not found\n",
    "\n",
    "        # Add the current image as the last channel again\n",
    "        #images.append(current_image)\n",
    "        #image_paths.append(current_image_path)\n",
    "\n",
    "        # Stack images to form a multi-channel image\n",
    "        multi_channel_image = torch.cat(images, dim=0)\n",
    "\n",
    "        return {'R': R, 'Z': Z, 'dBZ': dBZ, 'x': x, 'image': multi_channel_image} #, 'image_paths': image_paths}\n",
    "\n",
    "    def get_image_path(self, timestamp, station_id):\n",
    "        # Convert timestamp to the string format used in filenames\n",
    "        timestamp_str = timestamp.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        # Construct the full path of the image\n",
    "        path = os.path.join(self.image_dir, f'{timestamp.year}/{timestamp.month:02}/{timestamp.day:02}/{timestamp.hour:02}{timestamp.minute:02}', f'cropped_{timestamp_str}_{station_id}_63.png')\n",
    "        #print(f'Constructed image path: {path}')  # Debug print to check constructed paths\n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image_array, row, col, size):\n",
    "    \"\"\"\n",
    "    Crop a square patch of size (size, size) from the image_array centered at (row, col).\n",
    "    \"\"\"\n",
    "    half_size = size // 2\n",
    "    cropped_image = image_array[\n",
    "        row - half_size:row + half_size + 1,\n",
    "        col - half_size:col + half_size + 1\n",
    "    ]\n",
    "    return cropped_image\n",
    "\n",
    "def min_max_normalize(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "\n",
    "class ZR_dataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir='C:/Users/Henri/Emilie/Thesis/data/images/train', num_samples=1000):\n",
    "        self.df_full = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Convert 'timestamp' column to datetime\n",
    "        self.df_full['timestamp'] = pd.to_datetime(self.df_full['timestamp'])\n",
    "        \n",
    "        # Filter the rows where the minute value is a multiple of 10\n",
    "        mask = (self.df_full['timestamp'].dt.minute % 10 == 0) & \\\n",
    "               (self.df_full['R'].notnull()) & (self.df_full['Z'].notnull()) & \\\n",
    "               (self.df_full['R'] != 0) & (self.df_full['Z'] != 0)\n",
    "        self.df_filtered = self.df_full[mask]\n",
    "        \n",
    "        ## Sample indices without replacement from the filtered DataFrame\n",
    "        #if len(self.df_filtered) > num_samples:\n",
    "        #    self.sampled_indices = np.random.choice(self.df_filtered.index, size=num_samples, replace=False)\n",
    "        #    self.df_sampled = self.df_filtered.loc[self.sampled_indices]\n",
    "        #else:\n",
    "        self.df_sampled = self.df_filtered\n",
    "        \n",
    "        # Reset index of the sampled DataFrame\n",
    "        self.df_sampled.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Convert relevant columns to float and to a NumPy array for faster access\n",
    "        self.features = self.df_sampled[['radar_norm', 'dist_coast', 'dist_radar', 'topo', 'toy_sin', 'toy_cos', 'tod_sin', 'tod_cos']].astype(float).values\n",
    "        self.R = self.df_sampled['R'].astype(float).values\n",
    "        self.Z = self.df_sampled['Z'].astype(float).values\n",
    "        self.dBZ = self.df_sampled['dBZ'].astype(float).values\n",
    "        self.image_paths = self.df_sampled['cropped_radar_image_path'].values  # Load image paths\n",
    "        self.station_ids = self.df_sampled['stationId'].values  # Load station IDs\n",
    "        self.image_dir = image_dir\n",
    "        self.r_idx = self.df_sampled['r_idx'].astype(int).values  # Load row indices\n",
    "        self.c_idx = self.df_sampled['c_idx'].astype(int).values  # Load column indices\n",
    "        \n",
    "        # Load the additional image arrays\n",
    "        self.topo_image = np.load('topo_01.npy')\n",
    "        self.dist_radar_image = np.load('dist_radar_01.npy')\n",
    "        self.dist_coast_image = np.load('climate.npy')\n",
    "        \n",
    "        self.dist_coast_image = min_max_normalize(self.dist_coast_image)\n",
    "        self.dist_radar_image = min_max_normalize(self.dist_radar_image)\n",
    "        self.topo_image = min_max_normalize(self.topo_image)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.R)  # Return the length of the sampled DataFrame\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Directly access the pre-converted numpy arrays\n",
    "        x = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        R = torch.tensor(self.R[idx], dtype=torch.float)\n",
    "        Z = torch.tensor(self.Z[idx], dtype=torch.float)\n",
    "        dBZ = torch.tensor(self.dBZ[idx], dtype=torch.float)\n",
    "        \n",
    "        # Load the current image and its timestamp\n",
    "        current_image_path = self.image_paths[idx]\n",
    "        current_image = Image.open(current_image_path)\n",
    "        current_image = ToTensor()(current_image)  # Converts the image to a PyTorch tensor and normalizes to [0, 1]\n",
    "\n",
    "        # Parse the timestamp from the image filename\n",
    "        timestamp_str = os.path.basename(current_image_path).split('_')[1] + '_' + os.path.basename(current_image_path).split('_')[2]\n",
    "        try:\n",
    "            timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d_%H-%M-%S')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d')\n",
    "            except ValueError as e:\n",
    "                raise ValueError(f\"Unexpected timestamp format in filename: {current_image_path}\") from e\n",
    "        \n",
    "        # Get the station ID\n",
    "        station_id = self.station_ids[idx]\n",
    "\n",
    "        # Define time offsets including the current timestamp\n",
    "        time_offsets = [\n",
    "            timedelta(minutes=0),\n",
    "            timedelta(minutes=10),\n",
    "            timedelta(minutes=20),\n",
    "            timedelta(minutes=30),\n",
    "            timedelta(minutes=40),\n",
    "            timedelta(minutes=50),\n",
    "            timedelta(minutes=60)\n",
    "        ]\n",
    "\n",
    "        # Initialize a list to hold images and image paths\n",
    "        images = []\n",
    "        image_paths = []\n",
    "\n",
    "        for offset in time_offsets:\n",
    "            past_timestamp = timestamp - offset\n",
    "            past_image_path = self.get_image_path(past_timestamp, station_id)\n",
    "            #print(f'Loading image from: {past_image_path}')  # Debug print to check image paths\n",
    "            image_paths.append(past_image_path)\n",
    "            if past_image_path and os.path.exists(past_image_path):\n",
    "                past_image = Image.open(past_image_path)\n",
    "                past_image = ToTensor()(past_image)\n",
    "                images.append(past_image)\n",
    "            else:\n",
    "                #print(f'Image not found, using blank image for: {past_image_path}')  # Debug print for missing images\n",
    "                images.append(torch.zeros_like(current_image))  # Use a blank image if the past image is not found\n",
    "\n",
    "        # Add the current image as the last channel again\n",
    "        # Crop additional image channels\n",
    "        row = self.r_idx[idx]\n",
    "        col = self.c_idx[idx]\n",
    "        topo_crop = crop_image(self.topo_image, row, col, 63)\n",
    "        dist_radar_crop = crop_image(self.dist_radar_image, row, col, 63)\n",
    "        dist_coast_crop = crop_image(self.dist_coast_image, row, col, 63)\n",
    "        \n",
    "        # Convert these cropped images to tensors and normalize them\n",
    "        topo_crop = ToTensor()(topo_crop).float()\n",
    "        dist_radar_crop = ToTensor()(dist_radar_crop).float()\n",
    "        dist_coast_crop = ToTensor()(dist_coast_crop).float()\n",
    "\n",
    "        # Add the cropped images as additional channels\n",
    "        images.append(topo_crop)\n",
    "        images.append(dist_radar_crop)\n",
    "        images.append(dist_coast_crop)\n",
    "\n",
    "        # Stack images to form a multi-channel image\n",
    "        multi_channel_image = torch.cat(images, dim=0)\n",
    "\n",
    "        return {'R': R, 'Z': Z, 'dBZ': dBZ, 'x': x, 'image': multi_channel_image} #, 'image_paths': image_paths}\n",
    "\n",
    "    def get_image_path(self, timestamp, station_id):\n",
    "        # Convert timestamp to the string format used in filenames\n",
    "        timestamp_str = timestamp.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        # Construct the full path of the image\n",
    "        path = os.path.join(self.image_dir, f'{timestamp.year}/{timestamp.month:02}/{timestamp.day:02}/{timestamp.hour:02}{timestamp.minute:02}', f'cropped_{timestamp_str}_{station_id}_63.png')\n",
    "        #print(f'Constructed image path: {path}')  # Debug print to check constructed paths\n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "BATCH_SIZE = 1024\n",
    "train_dataset = ZR_dataset(csv_file=base_path + f'/data/trainZR_v3_63.csv')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)#, num_workers=4, pin_memory=True)\n",
    "\n",
    "validation_dataset = ZR_dataset(csv_file=base_path + f'/data/valZR_v3_63.csv')\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)#, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Function to plot radar images and print features along with image paths\n",
    "def visualize_batch(batch, num_images=4):\n",
    "    images = batch['image']\n",
    "    features = batch['x']\n",
    "    R = batch['R']\n",
    "    Z = batch['Z']\n",
    "    dBZ = batch['dBZ']\n",
    "    #image_paths = batch['image_paths']\n",
    "    \n",
    "    num_images = min(num_images, len(images))\n",
    "    num_channels = images.shape[1]\n",
    "\n",
    "    fig, axs = plt.subplots(num_images, num_channels, figsize=(num_channels * 5, num_images * 5))\n",
    "\n",
    "    # Ensure axs is a 2D array\n",
    "    if num_images == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)\n",
    "    if num_channels == 1:\n",
    "        axs = np.expand_dims(axs, axis=1)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        img = images[i].numpy()\n",
    "        feature_str = ', '.join([f'{feature:.2f}' for feature in features[i].numpy()])\n",
    "\n",
    "        for j in range(num_channels):\n",
    "            ax = axs[i, j]\n",
    "            ax.imshow(img[j, :, :], cmap='turbo')\n",
    "            ax.axis('off')\n",
    "            #image_path = image_paths[j][i]  # Get the corresponding image path\n",
    "            title_path = 'None'#image_path[-32:]  # Extract the last 32 characters of the image path\n",
    "            if j == 0:\n",
    "                ax.set_title(f'0-lagged Image\\n{title_path}\\nFeatures: {feature_str}\\n R: {R[i].item():.2f} | Z: {Z[i].item():.2f} | dBZ: {dBZ[i].item():.2f}')\n",
    "            else:\n",
    "                ax.set_title(f'{j*10}-lagged Image\\n{title_path}')\n",
    "                \n",
    "            #print(np.isnan(img[j, :, :]).sum())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define paths\n",
    "csv_file = base_path + '/data/trainZR_v3.csv'\n",
    "image_dir = base_path + '/data/images/train'\n",
    "\n",
    "# Get a batch from the DataLoader\n",
    "for batch in train_dataloader:\n",
    "    visualize_batch(batch, num_images=4)\n",
    "    break  # Only visualize one batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_features=11, dropout_rate=0.1, cnn_dropout_rate=0.25):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        # Image processing layers with added batch normalization and spatial dropout\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),  # Add batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(cnn_dropout_rate),  # Replace with spatial dropout\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),  # Add batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(cnn_dropout_rate),  # Replace with spatial dropout\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(64),  # Add batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Compute the size of the flattened features after convolution and pooling\n",
    "        reduced_image_size = 15  # From the final convolution layer with pooling\n",
    "        total_image_features = 64 * (reduced_image_size ** 2)\n",
    "\n",
    "        # Total features after concatenation\n",
    "        concatenated_features = total_image_features + input_features\n",
    "\n",
    "        # Define layers to learn A and B from features, including dropout\n",
    "        self.to_A = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1)  # Outputs A for given features\n",
    "        )\n",
    "        self.to_B = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1)  # Outputs B for given features\n",
    "        )\n",
    "\n",
    "        # Adjusted to_R with Batch Normalization\n",
    "        self.to_R = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            nn.BatchNorm1d(512),  # Add BatchNorm after Linear layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),  # Add BatchNorm after Linear layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            #nn.BatchNorm1d(128),  # Add BatchNorm after Linear layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 1)  # Outputs R for given features\n",
    "        )\n",
    "\n",
    "    def forward(self, x, image):\n",
    "        image_features = self.conv_layers(image)\n",
    "        # Concatenate image features with other features\n",
    "        combined_features = torch.cat((image_features, x), dim=1)\n",
    "        \n",
    "        logA = F.softplus(self.to_A(combined_features))\n",
    "        B = F.softplus(self.to_B(combined_features))\n",
    "        logR = self.to_R(combined_features)\n",
    "        \n",
    "        return logA, B, logR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_features=8, dropout_rate=0.1, cnn_dropout_rate=0.5, num_image_channels=11):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(num_image_channels, 8, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(cnn_dropout_rate),\n",
    "\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(cnn_dropout_rate),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(cnn_dropout_rate),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(cnn_dropout_rate),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.fc_x = nn.Sequential(\n",
    "            nn.Linear(input_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        image_feature_dim = 128\n",
    "        x_feature_dim = 128\n",
    "        concatenated_features = image_feature_dim + x_feature_dim\n",
    "\n",
    "        self.to_A = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softplus()  # Ensure positive output\n",
    "        )\n",
    "        self.to_B = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softplus()  # Ensure positive output\n",
    "        )\n",
    "        self.to_R = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 256),\n",
    "            #nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            #nn.BatchNorm1d(128),\n",
    "            #nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, image):\n",
    "        image_features = self.conv_layers(image)\n",
    "        image_features = image_features.view(image_features.size(0), -1)\n",
    "\n",
    "        x_features = self.fc_x(x)\n",
    "\n",
    "        combined_features = torch.cat((image_features, x_features), dim=1)\n",
    "\n",
    "        logA = self.to_A(combined_features)\n",
    "        B = self.to_B(combined_features)\n",
    "        logR = self.to_R(combined_features)\n",
    "\n",
    "        return logA, B, logR\n",
    "\n",
    "\n",
    "# Custom weight initialization\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_features=11, dropout_rate=0.1, cnn_dropout_rate=0.25):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        # Image processing layers with added batch normalization and spatial dropout\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),  # Add batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(cnn_dropout_rate),  # Replace with spatial dropout\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),  # Add batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(cnn_dropout_rate),  # Replace with spatial dropout\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(64),  # Add batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Compute the size of the flattened features after convolution and pooling\n",
    "        reduced_image_size = 15  # From the final convolution layer with pooling\n",
    "        total_image_features = 64 * (reduced_image_size ** 2)\n",
    "\n",
    "        # Total features after concatenation\n",
    "        concatenated_features = total_image_features + input_features\n",
    "\n",
    "        # Define layers to learn A and B from features, including dropout\n",
    "        self.to_A = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1)  # Outputs A for given features\n",
    "        )\n",
    "        self.to_B = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1)  # Outputs B for given features\n",
    "        )\n",
    "\n",
    "        # Adjusted to_R with Batch Normalization\n",
    "        self.to_R = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            nn.BatchNorm1d(512),  # Add BatchNorm after Linear layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),  # Add BatchNorm after Linear layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            #nn.BatchNorm1d(128),  # Add BatchNorm after Linear layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 1)  # Outputs R for given features\n",
    "        )\n",
    "\n",
    "    def forward(self, x, image):\n",
    "        image_features = self.conv_layers(image)\n",
    "        # Concatenate image features with other features\n",
    "        combined_features = torch.cat((image_features, x), dim=1)\n",
    "        \n",
    "        logA = F.softplus(self.to_A(combined_features))\n",
    "        B = F.softplus(self.to_B(combined_features))\n",
    "        logR = self.to_R(combined_features)\n",
    "        \n",
    "        return logA, B, logR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_features=8, dropout_rate=0.1, cnn_dropout_rate=0.1, num_image_channels=10):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        # Image processing layers with added batch normalization and spatial dropout\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(num_image_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),  # Add batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(cnn_dropout_rate),  # Replace with spatial dropout\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),  # Add batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(cnn_dropout_rate),  # Replace with spatial dropout\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),  # Add batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Compute the size of the flattened features after convolution and pooling\n",
    "        reduced_image_size = 15  # From the final convolution layer with pooling\n",
    "        total_image_features = 64 * (reduced_image_size ** 2)\n",
    "\n",
    "        # Total features after concatenation\n",
    "        concatenated_features = total_image_features + input_features\n",
    "\n",
    "        # Define layers to learn A and B from features, including dropout\n",
    "        self.to_A = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1)  # Outputs A for given features\n",
    "        )\n",
    "        self.to_B = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1)  # Outputs B for given features\n",
    "        )\n",
    "\n",
    "        # Adjusted to_R with Batch Normalization\n",
    "        self.to_R = nn.Sequential(\n",
    "            nn.Linear(concatenated_features, 512),\n",
    "            nn.BatchNorm1d(512),  # Add BatchNorm after Linear layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),  # Add BatchNorm after Linear layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 1)  # Outputs R for given features\n",
    "        )\n",
    "\n",
    "    def forward(self, x, image):\n",
    "        image_features = self.conv_layers(image)\n",
    "        # Concatenate image features with other features\n",
    "        combined_features = torch.cat((image_features, x), dim=1)\n",
    "        \n",
    "        logA = F.softplus(self.to_A(combined_features))\n",
    "        B = F.softplus(self.to_B(combined_features))\n",
    "        logR = self.to_R(combined_features)\n",
    "        \n",
    "        return logA, B, logR\n",
    "\n",
    "# Create the model\n",
    "model = NN(input_features=8, dropout_rate=0.1, cnn_dropout_rate=0.1, num_image_channels=10)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(model, batch, device, alpha = 0.5):\n",
    "    logZ = torch.log(batch['Z'].unsqueeze(1).to(device))\n",
    "    logA, B, logR_pred = model(batch['x'].to(device), batch['image'].to(device))\n",
    "    logR_true = torch.log(batch['R'].unsqueeze(1).to(device) * 60)  # Adjust units as necessary\n",
    "    \n",
    "    # Assuming A and B are constants for now, but they could be parameters of the model\n",
    "    mse_loss = nn.MSELoss()\n",
    "    data_loss = mse_loss(logR_pred, logR_true)\n",
    "    physics_loss  = mse_loss(logR_pred, (logZ - logA)/B)\n",
    "    total_loss = alpha * data_loss + (1 - alpha) * physics_loss\n",
    "    return total_loss, data_loss, physics_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(model, batch, device, alpha=0.5, beta=1.0, epsilon=1e-10):\n",
    "    logZ = torch.log(batch['Z'].unsqueeze(1).to(device))\n",
    "    logA, B, logR_pred = model(batch['x'].to(device), batch['image'].to(device))\n",
    "    \n",
    "    R_true = batch['R'].unsqueeze(1).to(device) * 60  # Adjust units as necessary\n",
    "    logR_true = torch.log(R_true + epsilon)  # Use epsilon to avoid log(0)\n",
    "    \n",
    "    mse_loss = nn.MSELoss(reduction='none')\n",
    "    data_loss = mse_loss(logR_pred, logR_true)\n",
    "    \n",
    "    physics_target = (logZ - logA) / B\n",
    "    \n",
    "    # Mask where R is zero for physics loss\n",
    "    mask = (R_true > epsilon).float()\n",
    "    physics_loss = mse_loss(logR_pred, physics_target) * mask\n",
    "    \n",
    "    # Weighting scheme to emphasize both small and large values\n",
    "    weights = torch.exp(logR_true - torch.min(logR_true))  # Exponential for high values\n",
    "\n",
    "    # Apply weights to data loss and physics loss\n",
    "    weighted_data_loss = (data_loss * weights).mean()\n",
    "    weighted_physics_loss = (physics_loss * weights).mean()\n",
    "    \n",
    "    total_loss = alpha * weighted_data_loss + (1 - alpha) * weighted_physics_loss\n",
    "    return total_loss, weighted_data_loss, weighted_physics_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(model, batch, device, alpha=0.5, beta=1.0):\n",
    "    logZ = torch.log(batch['Z'].unsqueeze(1).to(device))\n",
    "    logA, B, logR_pred = model(batch['x'].to(device), batch['image'].to(device))\n",
    "    logR_true = torch.log(batch['R'].unsqueeze(1).to(device) * 60)  # Adjust units as necessary\n",
    "\n",
    "    mse_loss = nn.MSELoss(reduction='none')\n",
    "    data_loss = mse_loss(logR_pred, logR_true)\n",
    "    physics_loss = mse_loss(logR_pred, (logZ - logA) / B)\n",
    "    \n",
    "    # Weight the data loss more for higher intensities\n",
    "    weights = torch.exp(logR_true - torch.min(logR_true))  # Exponential to increase weight for high values\n",
    "    weighted_data_loss = (data_loss * weights).mean()\n",
    "    weighted_physics_loss = (physics_loss).mean()\n",
    "    \n",
    "    total_loss = alpha * weighted_data_loss + (1 - alpha) * weighted_physics_loss\n",
    "    return total_loss, weighted_data_loss, weighted_physics_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "start_time = time.time() # Track the start time of the training process\n",
    "\n",
    "# Adjustable hyperparameters\n",
    "NUM_EPOCHS = 200 #40\n",
    "LEARNING_RATE = 0.001 #0.001 #1e-06 No dropout\n",
    "BATCH_SIZE = 1024\n",
    "WEIGHT_DECAY = 0.001\n",
    "ALPHA = 0.5\n",
    "epsilon = 1e-6 \n",
    "l1_lambda = 0.01\n",
    "\n",
    "TYPE = 'PINN_CNN_Imagetopoint'\n",
    "param_string = f\"L1, E = {NUM_EPOCHS}, LR = {LEARNING_RATE}, BS = {BATCH_SIZE}, WD = {WEIGHT_DECAY}, alpha = {ALPHA}_\"\n",
    "\n",
    "# Define early stopping parameters\n",
    "early_stopping_rounds = 10  # Number of epochs to wait for improvement\n",
    "best_validation_loss = float('inf')\n",
    "no_improvement_count = 0\n",
    "\n",
    "# Check if CUDA is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# For plotting\n",
    "train_losses = []\n",
    "train_physics_losses = []\n",
    "train_data_losses = []\n",
    "\n",
    "validation_losses = []\n",
    "validation_physics_losses = []\n",
    "validation_data_losses = []\n",
    "\n",
    "\n",
    "prev_avg_data_loss = None\n",
    "prev_avg_physics_loss = None\n",
    "\n",
    "# Optimizer - optimize A and B directly\n",
    "#model = NN(input_features=8).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_epoch_loss = 0\n",
    "    data_epoch_loss = 0\n",
    "    physics_epoch_loss = 0\n",
    "    l1_epoch_loss = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "        optimizer.zero_grad() \n",
    "        total_loss, data_loss, physics_loss = combined_loss(model, batch, device, alpha = ALPHA)\n",
    "        \n",
    "        l1_penalty = sum(p.abs().sum() for p in model.parameters())\n",
    "        \n",
    "        # Total loss with L1 regularization\n",
    "        loss_with_l1 = total_loss + l1_lambda * l1_penalty\n",
    "        \n",
    "        loss_with_l1.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_epoch_loss += total_loss.item()\n",
    "        data_epoch_loss += data_loss.item()\n",
    "        physics_epoch_loss += physics_loss.item()\n",
    "        l1_epoch_loss += l1_penalty.item()\n",
    "\n",
    "    # Calculate average loss over the epoch\n",
    "    avg_epoch_loss = total_epoch_loss / len(train_dataloader)\n",
    "    avg_data_loss = data_epoch_loss / len(train_dataloader)\n",
    "    avg_physics_loss = physics_epoch_loss / len(train_dataloader)\n",
    "    \n",
    "    # Update previous losses for the next epoch\n",
    "    prev_avg_data_loss = avg_data_loss\n",
    "    prev_avg_physics_loss = avg_physics_loss\n",
    "\n",
    "    train_losses.append(avg_epoch_loss)\n",
    "    train_data_losses.append(avg_data_loss)\n",
    "    train_physics_losses.append(avg_physics_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():  # No need to track gradients during validation\n",
    "        total_validation_loss = 0\n",
    "        validation_data_loss = 0\n",
    "        validation_physics_loss = 0\n",
    "        for batch in validation_dataloader:\n",
    "            batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "            total_loss, data_loss, physics_loss = combined_loss(model, batch, device, alpha = ALPHA)\n",
    "\n",
    "            total_validation_loss += total_loss.item()\n",
    "            validation_data_loss += data_loss.item()\n",
    "            validation_physics_loss += physics_loss.item()          \n",
    "\n",
    "        avg_validation_loss = total_validation_loss / len(validation_dataloader)\n",
    "        avg_validation_data_loss = validation_data_loss / len(validation_dataloader)\n",
    "        avg_validation_physics_loss = validation_physics_loss / len(validation_dataloader)\n",
    "\n",
    "        validation_losses.append(avg_validation_loss)\n",
    "        validation_data_losses.append(avg_validation_data_loss)\n",
    "        validation_physics_losses.append(avg_validation_physics_loss)\n",
    "        \n",
    "        scheduler.step(avg_validation_loss)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {avg_epoch_loss}, Validation Loss: {avg_validation_loss}, Alpha: {ALPHA}\")\n",
    "    \n",
    "    # Check for early stopping\n",
    "    if avg_validation_loss < best_validation_loss:\n",
    "        best_validation_loss = avg_validation_loss\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "        if no_improvement_count >= early_stopping_rounds:\n",
    "            print(f\"Early stopping at epoch {epoch + 1} as validation loss didn't improve for {early_stopping_rounds} epochs.\")\n",
    "            break\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training took {elapsed_time/60:.2f} min.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(epoch + 1)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4)) \n",
    "\n",
    "# Plot training and validation losses\n",
    "axs[0].plot(epochs, train_losses, color = 'black', label = 'training loss')\n",
    "axs[0].plot(epochs, validation_losses, color = 'darkorange', label = 'validation loss')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Total loss')\n",
    "#axs[0].set_ylim(0, 100)\n",
    "\n",
    "# Plot training and validation losses\n",
    "axs[1].plot(epochs, train_physics_losses, color = 'black', label = 'training loss')\n",
    "axs[1].plot(epochs, validation_physics_losses, color = 'darkorange', label = 'validation loss')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Physics loss')\n",
    "#axs[1].set_ylim(0, 100)\n",
    "\n",
    "# Plot training and validation losses\n",
    "axs[2].plot(epochs, train_data_losses, color = 'black', label = 'training loss')\n",
    "axs[2].plot(epochs, validation_data_losses, color = 'darkorange', label = 'validation loss')\n",
    "axs[2].set_xlabel('Epochs')\n",
    "axs[2].set_ylabel('Loss')\n",
    "axs[2].legend()\n",
    "axs[2].set_title('Data loss')\n",
    "#xs[2].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = param_string + 'model_conv2' + '.png'\n",
    "plt.savefig(save_path, bbox_inches='tight', pad_inches=0.01, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluatuion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZR_test_dataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir='C:/Users/Henri/Emilie/Thesis/data/images/test', num_samples=None):\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Convert 'timestamp' column to datetime\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        \n",
    "        # Filter the rows where the minute value is a multiple of 10\n",
    "        df = df[df['timestamp'].dt.minute % 10 == 0]\n",
    "        \n",
    "        df = df[(df['R'] != 0) & (df['Z'] != 0) & ~df['R'].isnull() & ~df['Z'].isnull()]\n",
    "        \n",
    "        if num_samples is not None:\n",
    "            df = df.sample(n=num_samples, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        self.sampled_indices = df.index\n",
    "\n",
    "        # Create a sampled DataFrame based on the sampled indices\n",
    "        self.df_sampled = df.loc[self.sampled_indices].reset_index(drop=True)\n",
    "\n",
    "        # Convert relevant columns to float and to a NumPy array for faster access\n",
    "        self.features = self.df_sampled[['radar_norm', 'dist_coast', 'dist_radar', 'topo', 'toy_sin', 'toy_cos', 'tod_sin', 'tod_cos']].astype(float).values\n",
    "        self.R = self.df_sampled['R'].astype(float).values\n",
    "        self.Z = self.df_sampled['Z'].astype(float).values\n",
    "        self.dBZ = self.df_sampled['dBZ'].astype(float).values\n",
    "        self.image_paths = self.df_sampled['cropped_radar_image_path'].values  # Load image paths\n",
    "        self.station_ids = self.df_sampled['stationId'].values  # Load station IDs\n",
    "        self.r_idx = self.df_sampled['r_idx'].astype(int).values  # Load row indices\n",
    "        self.c_idx = self.df_sampled['c_idx'].astype(int).values  # Load column indices\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "        # Load the additional image arrays\n",
    "        self.topo_image = np.load('topo_01.npy')\n",
    "        self.dist_radar_image = np.load('dist_radar_01.npy')\n",
    "        self.dist_coast_image = np.load('climate.npy')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.R)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Directly access the pre-converted numpy arrays\n",
    "        x = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        R = torch.tensor(self.R[idx], dtype=torch.float)\n",
    "        Z = torch.tensor(self.Z[idx], dtype=torch.float)\n",
    "        dBZ = torch.tensor(self.dBZ[idx], dtype=torch.float)\n",
    "\n",
    "        # Load the current image and its timestamp\n",
    "        current_image_path = self.image_paths[idx]\n",
    "        current_image = Image.open(current_image_path)\n",
    "        current_image = ToTensor()(current_image)  # Converts the image to a PyTorch tensor and normalizes to [0, 1]\n",
    "\n",
    "        # Parse the timestamp from the image filename\n",
    "        timestamp_str = os.path.basename(current_image_path).split('_')[1] + '_' + os.path.basename(current_image_path).split('_')[2]\n",
    "        try:\n",
    "            timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d_%H-%M-%S')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d')\n",
    "            except ValueError as e:\n",
    "                raise ValueError(f\"Unexpected timestamp format in filename: {current_image_path}\") from e\n",
    "\n",
    "        # Get the station ID\n",
    "        station_id = self.station_ids[idx]\n",
    "\n",
    "        # Define time offsets including the current timestamp\n",
    "        time_offsets = [\n",
    "            timedelta(minutes=0),\n",
    "            timedelta(minutes=10),\n",
    "            timedelta(minutes=20),\n",
    "            timedelta(minutes=30),\n",
    "            timedelta(minutes=40),\n",
    "            timedelta(minutes=50),\n",
    "            timedelta(minutes=60)\n",
    "        ]\n",
    "\n",
    "        # Initialize a list to hold images\n",
    "        images = []\n",
    "\n",
    "        for offset in time_offsets:\n",
    "            past_timestamp = timestamp - offset\n",
    "            past_image_path = self.get_image_path(past_timestamp, station_id)\n",
    "            if past_image_path and os.path.exists(past_image_path):\n",
    "                past_image = Image.open(past_image_path)\n",
    "                past_image = ToTensor()(past_image)\n",
    "                images.append(past_image)\n",
    "            else:\n",
    "                images.append(torch.zeros_like(current_image))  # Use a blank image if the past image is not found\n",
    "\n",
    "        # Crop additional image channels\n",
    "        row = self.r_idx[idx]\n",
    "        col = self.c_idx[idx]\n",
    "        topo_crop = crop_image(self.topo_image, row, col, 63)\n",
    "        dist_radar_crop = crop_image(self.dist_radar_image, row, col, 63)\n",
    "        dist_coast_crop = crop_image(self.dist_coast_image, row, col, 63)\n",
    "\n",
    "        # Convert these cropped images to tensors and normalize them\n",
    "        topo_crop = ToTensor()(topo_crop).float()\n",
    "        dist_radar_crop = ToTensor()(dist_radar_crop).float()\n",
    "        dist_coast_crop = ToTensor()(dist_coast_crop).float()\n",
    "\n",
    "        # Add the cropped images as additional channels\n",
    "        images.append(topo_crop)\n",
    "        images.append(dist_radar_crop)\n",
    "        images.append(dist_coast_crop)\n",
    "\n",
    "        # Stack images to form a multi-channel image\n",
    "        multi_channel_image = torch.cat(images, dim=0)\n",
    "\n",
    "        return {'R': R, 'Z': Z, 'dBZ': dBZ, 'x': x, 'image': multi_channel_image}\n",
    "\n",
    "    def get_image_path(self, timestamp, station_id):\n",
    "        # Convert timestamp to the string format used in filenames\n",
    "        timestamp_str = timestamp.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        # Construct the full path of the image\n",
    "        path = os.path.join(self.image_dir, f'{timestamp.year}/{timestamp.month:02}/{timestamp.day:02}/{timestamp.hour:02}{timestamp.minute:02}', f'cropped_{timestamp_str}_{station_id}_63.png')\n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_dataset = ZR_test_dataset(csv_file=base_path + f'/data/testZR_v3_63.csv')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "logAs = []  \n",
    "Bs = []\n",
    "logR_preds = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for batch in tqdm(test_dataloader):\n",
    "        features = batch['x'].to(device)\n",
    "        images = batch['image'].to(device)\n",
    "\n",
    "        # Make predictions\n",
    "        logA, B, x = model(features, images)\n",
    "\n",
    "        # Collect predictions\n",
    "        logAs.append(logA)\n",
    "        Bs.append(B)\n",
    "        logR_preds.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "df_test = pd.read_csv(base_path + f'/data/testZR_v3_63.csv')\n",
    "df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
    "df_test = df_test[df_test['timestamp'].dt.minute % 10 == 0]\n",
    "\n",
    "df_test.head()\n",
    "\n",
    "# Convert to appropriate types or calculate fields for entire DataFrame\n",
    "df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
    "df_test['year'] = df_test['timestamp'].dt.year\n",
    "df_test['month'] = df_test['timestamp'].dt.month\n",
    "\n",
    "# Temporary fields to handle calculations (these can be adjusted later as needed)\n",
    "df_test['R_true'] = np.array(df_test['R'] * 60)  # Convert R to the right unit for the whole DataFrame\n",
    "\n",
    "# Identify rows where R and Z are not zero or NaN\n",
    "valid_idx = df_test[(df_test['R'] != 0) & (df_test['Z'] != 0) & ~df_test['R'].isnull() & ~df_test['Z'].isnull()].index\n",
    "\n",
    "# Apply calculations only for valid rows\n",
    "df_test[['MP', 'MP_opt', 'R_pred_R', 'R_pred_AB']] = 0.0\n",
    "df_test.loc[valid_idx, 'MP'] = np.array(pf.dbz_to_R_marshall_palmer(df_test.loc[valid_idx, 'dBZ'], 200, 1.6)).astype(float)\n",
    "A_est = 196.0\n",
    "B_est = 3.4\n",
    "df_test.loc[valid_idx, 'MP_opt'] = np.array(pf.dbz_to_R_marshall_palmer(df_test.loc[valid_idx, 'dBZ'], A_est, B_est)).astype(float)\n",
    "df_test.loc[valid_idx, 'A'] = np.exp(torch.cat(logAs).cpu().numpy())\n",
    "df_test.loc[valid_idx, 'B'] = torch.cat(Bs).cpu().numpy()\n",
    "df_test.loc[valid_idx, 'R_pred_R'] = np.exp(torch.cat(logR_preds).cpu().numpy())\n",
    "df_test.loc[valid_idx, 'R_pred_AB'] = np.array(pf.dbz_to_R_marshall_palmer(df_test.loc[valid_idx, 'dBZ'], df_test.loc[valid_idx, 'A'], df_test.loc[valid_idx, 'B']))\n",
    "\n",
    "# Calculate errors only for valid rows\n",
    "df_test['error_standard'] = df_test['R_true'] - df_test['MP']\n",
    "df_test['error_pred_R'] = df_test['R_true'] - df_test['R_pred_R']\n",
    "df_test['error_pred_AB'] = df_test['R_true'] - df_test['R_pred_AB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.cat(logR_preds).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_string ='test'\n",
    "\n",
    "# Example 1\n",
    "pf.plot_hyetograph_m2(df_test, station_id=5049, \n",
    "               start_timestamp='2023-04-12 20:00:00', \n",
    "               end_timestamp='2023-04-13 08:30:00', \n",
    "               A_est=A_est, B_est=B_est, save_path = fig_string,\n",
    "               tick_interval=6)  \n",
    "\n",
    "# Example 2\n",
    "pf.plot_hyetograph_m2(df_test, station_id=5195,\n",
    "               start_timestamp='2023-07-26 09:00:00', \n",
    "               end_timestamp='2023-07-26 16:00:00', \n",
    "               A_est=A_est, B_est=B_est, save_path = fig_string,\n",
    "               tick_interval=6)  \n",
    "\n",
    "# Example 3\n",
    "pf.plot_hyetograph_m2(df_test, station_id=5049,\n",
    "               start_timestamp='2023-08-24 15:00:00', \n",
    "               end_timestamp='2023-08-25 08:00:00', \n",
    "               A_est=A_est, B_est=B_est, save_path = fig_string,\n",
    "               tick_interval=6)  \n",
    "\n",
    "# Example 4 \n",
    "pf.plot_hyetograph_m2(df_test, station_id=5340,\n",
    "               start_timestamp='2023-10-02 20:00:00', \n",
    "               end_timestamp='2023-10-03 11:00:00', \n",
    "               A_est=A_est, B_est=B_est, save_path = fig_string,\n",
    "               tick_interval=6)  \n",
    "\n",
    "# Example 5 \n",
    "pf.plot_hyetograph_m2(df_test, station_id=5340,\n",
    "               start_timestamp='2023-12-21 00:00:00', \n",
    "               end_timestamp='2023-12-21 11:00:00', \n",
    "               A_est=A_est, B_est=B_est, save_path = fig_string,\n",
    "               tick_interval=6)  \n",
    "\n",
    "# Example 6 \n",
    "pf.plot_hyetograph_m2(df_test, station_id=5732,\n",
    "               start_timestamp='2023-04-11 00:00:00', \n",
    "               end_timestamp='2023-04-11 18:00:00', \n",
    "               A_est=A_est, B_est=B_est, save_path = fig_string,\n",
    "               tick_interval=6)  \n",
    "\n",
    "# Example 7 \n",
    "pf.plot_hyetograph_m2(df_test, station_id=5461,\n",
    "               start_timestamp='2023-05-05 20:00:00', \n",
    "               end_timestamp='2023-05-06 09:00:00', \n",
    "               A_est=A_est, B_est=B_est, save_path = fig_string,\n",
    "               tick_interval=6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop rows where any of the specified columns have NaN values\n",
    "df_clean =  df_test.dropna(subset=['R_true', 'MP', 'R_pred_R', 'R_pred_AB', 'A', 'B'])\n",
    "\n",
    "metrics_MP = pf.evaluation_metrics(df_clean['R_true'], df_clean['MP'])\n",
    "metrics_MP_opt = pf.evaluation_metrics(df_clean['R_true'], df_clean['MP_opt'])\n",
    "metrics_R_pred_R = pf.evaluation_metrics(df_clean['R_true'], df_clean['R_pred_R'])\n",
    "metrics_R_pred_AB = pf.evaluation_metrics(df_clean['R_true'], df_clean['R_pred_AB'])\n",
    "\n",
    "# Create a DataFrame from the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'MP': metrics_MP,\n",
    "    'MP_opt': metrics_MP_opt,\n",
    "    'R_pred_R': metrics_R_pred_R,\n",
    "    'R_pred_AB': metrics_R_pred_AB\n",
    "})\n",
    "\n",
    "# Transpose the DataFrame to have models as rows and metrics as columns\n",
    "metrics_df = metrics_df.T\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import table\n",
    "\n",
    "# Create a figure and a single subplot\n",
    "fig, ax = plt.subplots(figsize=(8, 3))  # Adjust the figure size as needed\n",
    "\n",
    "# Hide the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Add a table at the bottom of the axes\n",
    "tbl = table(ax, metrics_df, loc='center')\n",
    "\n",
    "# Save the figure as an image file\n",
    "save_path = param_string + 'metrics' + '.png'\n",
    "plt.savefig(save_path, bbox_inches='tight', dpi=300)  # Adjust DPI as needed\n",
    "\n",
    "plt.show()\n",
    "# Optionally: close the figure\n",
    "#plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total absolute error MP_opt:', abs(df_test['R_true'].loc[valid_idx] / 6  -  df_test['MP_opt'].loc[valid_idx] / 6).sum())\n",
    "print('Total absolute error R:', abs(df_test['R_true'].loc[valid_idx] / 6  -  df_test['R_pred_R'].loc[valid_idx] / 6).sum())\n",
    "print('Total absolute error AB:', abs(df_test['R_true'].loc[valid_idx] / 6  -  df_test['R_pred_AB'].loc[valid_idx] / 6).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by Rain Intensity Group\n",
    "pf.plot_goruped_rain_intensity_error_m2(df_test.loc[valid_idx,:].copy(), TYPE = 'M3: Image-to-point PINN', save_path = fig_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot histograms of A and B\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 6))\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "axs[0].hist(df_test['A'][np.isfinite(df_test['A'])], color='black', alpha=0.7)\n",
    "#axs[0].set_title('Histogram of A')\n",
    "axs[0].set_xlabel('A')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "axs[4].hist(df_test['B'], bins=50, color='black', alpha=0.7)\n",
    "#axs[4].set_title('Histogram of B')\n",
    "axs[4].set_xlabel('B')\n",
    "axs[4].set_ylabel('Frequency')\n",
    "\n",
    "flierprops = dict(marker='.', markerfacecolor='black', markersize=2, linestyle='none')\n",
    "\n",
    "groups = df_clean.groupby('month')['A'].apply(list)\n",
    "data_for_boxplot = [group for name, group in groups.items()]\n",
    "axs[1].boxplot(data_for_boxplot, flierprops=flierprops)\n",
    "#axs[1].set_title('Boxplot of A by month')\n",
    "axs[1].set_xlabel('Month')\n",
    "axs[1].set_ylabel('A')\n",
    "\n",
    "groups = df_clean.groupby('month')['B'].apply(list)\n",
    "data_for_boxplot = [group for name, group in groups.items()]\n",
    "axs[5].boxplot(data_for_boxplot, flierprops=flierprops)\n",
    "#axs[5].set_title('Boxplot of B by month')\n",
    "axs[5].set_xlabel('Month')\n",
    "axs[5].set_ylabel('B')\n",
    "\n",
    "groups = df_clean.groupby('stationId')['A'].apply(list)\n",
    "data_for_boxplot = [group for name, group in groups.items()]\n",
    "station_ids = [name for name, group in groups.items()]\n",
    "axs[2].boxplot(data_for_boxplot, flierprops=flierprops,  labels=station_ids)\n",
    "#axs[2].set_title('Boxplot of A by station')\n",
    "axs[2].set_xlabel('Station ID')\n",
    "axs[2].set_xticklabels(station_ids, rotation=45) \n",
    "axs[2].set_ylabel('A')\n",
    "\n",
    "groups = df_clean.groupby('stationId')['B'].apply(list)\n",
    "data_for_boxplot = [group for name, group in groups.items()]\n",
    "axs[6].boxplot(data_for_boxplot, flierprops=flierprops,  labels=station_ids)\n",
    "#axs[6].set_title('Boxplot of B by station')\n",
    "axs[6].set_xlabel('Station ID')\n",
    "axs[6].set_xticklabels(station_ids, rotation=45) \n",
    "axs[6].set_ylabel('B')\n",
    "\n",
    "axs[3].scatter(df_clean['dBZ'], df_clean['A'], color='black', alpha=0.1, s= 1)\n",
    "#axs[3].set_title('Scatter plot of A and dBZ')\n",
    "axs[3].set_xlabel('dBZ')\n",
    "axs[3].set_ylabel('A')\n",
    "\n",
    "axs[7].scatter(df_clean['dBZ'], df_clean['B'], color='black', alpha=0.1, s= 1)\n",
    "#axs[7].set_title('Scatter plot of B and dBZ')\n",
    "axs[7].set_xlabel('dBZ')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = param_string + 'A_B' + '.png'\n",
    "plt.savefig(save_path, bbox_inches='tight', pad_inches=0.01, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_test[df_test['stationId'] == 5049]\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "R_pred_R = df_filtered['R_pred_R']\n",
    "R_pred_AB = df_filtered['R_pred_AB']\n",
    "R_true = df_filtered['R_true']\n",
    "MP = df_filtered['MP']\n",
    "MP_opt = df_filtered['MP_opt']\n",
    "\n",
    "idx = np.linspace(3120, 3270, 251, dtype=int)\n",
    "\n",
    "df_filtered['timestamp'] = pd.to_datetime(df_filtered['timestamp'])\n",
    "t = df_filtered['timestamp'][idx]\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(t, R_true[idx], label = 'Gauge', lw = 2, color = 'black')\n",
    "plt.plot(t, MP[idx], '--', label = 'Marshall-Palmer A=200, B=1.6', color = 'darkorange')\n",
    "plt.plot(t, R_pred_R[idx], '-', label = f'NN R', color = 'purple')\n",
    "#plt.plot(t, R_pred_AB[idx], '-', label = f'NN AB', color = 'dodgerblue')\n",
    "plt.plot(t, MP_opt[idx], '--', label = f'Marshall-Palmer A={A_est:0.4}, B={B_est:0.2}', color = 'green')\n",
    "plt.ylabel('Rain rate (mm/h)')\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) # labels along the bottom edge are off\n",
    "plt.legend()\n",
    "\n",
    "error_standard = R_true - MP\n",
    "error_R = R_true - R_pred_R\n",
    "error_AB = R_true - R_pred_AB\n",
    "error_MP_opt = R_true - MP_opt\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "#plt.plot(t, abs(error_standard[idx]), color = 'darkorange', label = 'Marshall-Palmer A=200, B=1.6')\n",
    "plt.plot(t, abs(error_R[idx]), color = 'purple', label = f'NN (R)')\n",
    "plt.plot(t, abs(error_AB[idx]), color = 'dodgerblue', label = f'NN (AB)')\n",
    "plt.plot(t, abs(error_MP_opt[idx]), '--', color = 'green', label = f'Marshall-Palmer A={A_est:0.4}, B={B_est:0.2}')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Absolute error')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = param_string + 'model2_ts'  + '.png'\n",
    "plt.savefig(save_path, bbox_inches='tight', pad_inches=0.01, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_test[df_test['stationId'] == 5049]\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "R_pred_R = df_filtered['R_pred_R']\n",
    "R_pred_AB = df_filtered['R_pred_AB']\n",
    "R_true = df_filtered['R_true']\n",
    "MP = df_filtered['MP']\n",
    "MP_opt = df_filtered['MP_opt']\n",
    "\n",
    "#idx = np.linspace(1150, 1300, 150, dtype=int)\n",
    "idx = np.linspace(6240, 6500, 260, dtype=int)\n",
    "df_filtered['timestamp'] = pd.to_datetime(df_filtered['timestamp'])\n",
    "t = df_filtered['timestamp'][idx]\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(t, R_true[idx], label = 'Gauge', lw = 3, color = 'black')\n",
    "#plt.plot(t, MP[idx], '--', label = 'Marshall-Palmer A=200, B=1.6', color = 'darkorange')\n",
    "plt.plot(t, R_pred_R[idx], '-', label = f'M2: R', color = 'purple')\n",
    "plt.plot(t, R_pred_AB[idx], '-', label = f'M2: AB', color = 'dodgerblue')\n",
    "plt.plot(t, MP_opt[idx], '--', label = f'M1: Marshall-Palmer A={A_est:0.4}, B={B_est:0.2}', color = 'green')\n",
    "plt.ylabel('Rain rate (mm/h)')\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) # labels along the bottom edge are off\n",
    "plt.legend()\n",
    "\n",
    "error_standard = R_true - MP\n",
    "error_R = R_true - R_pred_R\n",
    "error_AB = R_true - R_pred_AB\n",
    "error_MP_opt = R_true - MP_opt\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "#plt.plot(t, abs(error_standard[idx]), color = 'darkorange', label = 'Marshall-Palmer A=200, B=1.6')\n",
    "plt.plot(t, abs(error_R[idx]), color = 'purple', label = f'M2: R')\n",
    "plt.plot(t, abs(error_AB[idx]), color = 'dodgerblue', label = f'M2: AB')\n",
    "plt.plot(t, abs(error_MP_opt[idx]), '--', color = 'green', label = f'M1: Marshall-Palmer A={A_est:0.4}, B={B_est:0.2}')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Absolute error')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = param_string + 'model2_ts'  + '.png'\n",
    "plt.savefig(save_path, bbox_inches='tight', pad_inches=0.01, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_test is already defined and contains the necessary data\n",
    "\n",
    "TYPE = 'M3: Image-to-point PINN'\n",
    "# Group by 'stationId' and compute cumulative sums for each group\n",
    "grouped = df_test.groupby('stationId')\n",
    "\n",
    "# Initialize an empty dictionary to store cumulative sums\n",
    "cumulative_sums = {'timestamp': [], 'R_true': [], 'MP': [], 'MP_opt': [], 'R_pred_R': [], 'R_pred_AB': []}\n",
    "\n",
    "# Loop over each group and compute the cumulative sums\n",
    "for name, group in grouped:\n",
    "    group = group.sort_values('timestamp')  # Ensure the group is sorted by timestamp\n",
    "\n",
    "    # Remove rows with NaN values before computing cumulative sums\n",
    "    group = group.dropna(subset=['R_true', 'MP', 'MP_opt', 'R_pred_R', 'R_pred_AB'])\n",
    "\n",
    "    # Calculate cumulative sums\n",
    "    cumulative_sums['timestamp'].append(group['timestamp'].values)\n",
    "    cumulative_sums['R_true'].append(np.cumsum(group['R_true'].values))\n",
    "    cumulative_sums['MP'].append(np.cumsum(group['MP'].values))\n",
    "    cumulative_sums['MP_opt'].append(np.cumsum(group['MP_opt'].values))\n",
    "    cumulative_sums['R_pred_R'].append(np.cumsum(group['R_pred_R'].values))\n",
    "    cumulative_sums['R_pred_AB'].append(np.cumsum(group['R_pred_AB'].values))\n",
    "\n",
    "# Find the minimum length of all cumulative sum arrays\n",
    "min_length = min(len(arr) for arr in cumulative_sums['R_true'])\n",
    "\n",
    "# Truncate all arrays to the minimum length\n",
    "cumulative_sums['timestamp'] = [arr[:min_length] for arr in cumulative_sums['timestamp']]\n",
    "cumulative_sums['R_true'] = np.array([arr[:min_length] for arr in cumulative_sums['R_true']])\n",
    "cumulative_sums['MP'] = np.array([arr[:min_length] for arr in cumulative_sums['MP']])\n",
    "cumulative_sums['MP_opt'] = np.array([arr[:min_length] for arr in cumulative_sums['MP_opt']])\n",
    "cumulative_sums['R_pred_R'] = np.array([arr[:min_length] for arr in cumulative_sums['R_pred_R']])\n",
    "cumulative_sums['R_pred_AB'] = np.array([arr[:min_length] for arr in cumulative_sums['R_pred_AB']])\n",
    "\n",
    "# Compute the average cumulative sums across all stationIds\n",
    "avg_R_true = np.mean(cumulative_sums['R_true'], axis=0)\n",
    "avg_MP = np.mean(cumulative_sums['MP'], axis=0)\n",
    "avg_MP_opt = np.mean(cumulative_sums['MP_opt'], axis=0)\n",
    "avg_R_pred_R = np.mean(cumulative_sums['R_pred_R'], axis=0)\n",
    "avg_R_pred_AB = np.mean(cumulative_sums['R_pred_AB'], axis=0)\n",
    "\n",
    "# Handle timestamps separately\n",
    "# Convert timestamps to numerical values (e.g., Unix timestamps)\n",
    "timestamps_numeric = [ts[:min_length].astype(np.int64) for ts in cumulative_sums['timestamp']]\n",
    "timestamps_numeric = np.array(timestamps_numeric)\n",
    "avg_timestamp_numeric = np.mean(timestamps_numeric, axis=0)\n",
    "avg_timestamp = pd.to_datetime(avg_timestamp_numeric)\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12, 8))  # 1 Row, 1 Column\n",
    "\n",
    "# Plot the average cumulative sums\n",
    "axs.plot(avg_timestamp, avg_R_true, label='True Values', color='black', lw=3)\n",
    "axs.plot(avg_timestamp, avg_MP, label='M0: Standard Parameters', color = 'orangered', alpha = 0.8)\n",
    "axs.plot(avg_timestamp, avg_MP_opt, label='M1: Optimized Parameters', color = 'green', alpha = 0.8)\n",
    "axs.plot(avg_timestamp, avg_R_pred_R, label=f'{TYPE} (R)', color = 'blue', alpha = 0.8)\n",
    "axs.plot(avg_timestamp, avg_R_pred_AB, label=f'{TYPE} (AB)', color = 'purple', alpha = 0.8)\n",
    "axs.legend()\n",
    "axs.set_ylabel('mm/h')\n",
    "axs.set_title('Average Cumulative True and Predicted Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_test is already defined and contains the necessary data\n",
    "\n",
    "# Get unique station IDs\n",
    "station_ids = df_test['stationId'].unique()\n",
    "\n",
    "# Create a 4x4 grid of subplots\n",
    "fig, axs = plt.subplots(4, 4, figsize=(20, 16))  # 4 Rows, 4 Columns\n",
    "\n",
    "# Loop over each stationId and plot the cumulative values\n",
    "for i, station_id in enumerate(station_ids):\n",
    "    # Filter data for the current stationId\n",
    "    df_filtered = df_test[df_test['stationId'] == station_id].sort_values('timestamp')\n",
    "    \n",
    "    # Remove rows with NaN values\n",
    "    df_filtered = df_filtered.dropna(subset=['R_true', 'MP', 'MP_opt', 'R_pred_R', 'R_pred_AB'])\n",
    "    \n",
    "    # Compute cumulative sums\n",
    "    cumsum_R_true = np.cumsum(df_filtered['R_true'].values)\n",
    "    cumsum_MP = np.cumsum(df_filtered['MP'].values)\n",
    "    cumsum_MP_opt = np.cumsum(df_filtered['MP_opt'].values)\n",
    "    cumsum_R_pred_R = np.cumsum(df_filtered['R_pred_R'].values)\n",
    "    cumsum_R_pred_AB = np.cumsum(df_filtered['R_pred_AB'].values)\n",
    "    \n",
    "    # Get the subplot axes\n",
    "    ax = axs[i // 4, i % 4]\n",
    "    \n",
    "    # Plot cumulative sums\n",
    "    ax.plot(df_filtered['timestamp'], cumsum_R_true, label='True Values', color='black', lw=3)\n",
    "    ax.plot(df_filtered['timestamp'], cumsum_MP, label='M0: Standard Parameters', color = 'orangered', alpha = 0.8)\n",
    "    ax.plot(df_filtered['timestamp'], cumsum_MP_opt, label='M1: Optimized Parameters', color = 'green', alpha = 0.8)\n",
    "    ax.plot(df_filtered['timestamp'], cumsum_R_pred_R, label='M3: Image-to-point PINN (R)', color = 'blue', alpha = 0.8)\n",
    "    ax.plot(df_filtered['timestamp'], cumsum_R_pred_AB, label='M3: Image-to-point PINN (AB)', color = 'purple', alpha = 0.8)\n",
    "    \n",
    "    # Set plot title\n",
    "    ax.set_title(f'Station ID: {station_id}')\n",
    "    \n",
    "    # Set labels only on the leftmost column and bottom row\n",
    "    if i % 4 == 0:\n",
    "        ax.set_ylabel('mm/h')\n",
    "    if i // 4 == 3:\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_xticklabels(ax.get_xticks(), rotation=45)\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "    \n",
    "    # Only add legend to the first subplot\n",
    "    if i == 0:\n",
    "        ax.legend()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsMP = pf.calculate_metrics2(df_test, 'MP')\n",
    "metricsMP_opt = pf.calculate_metrics2(df_test, 'MP_opt')\n",
    "metricsR = pf.calculate_metrics2(df_test, 'R_pred_R')\n",
    "metricsAB = pf.calculate_metrics2(df_test, 'R_pred_AB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_error_metrics(metrics_df_MP, metrics_df_MP_opt, metrics_df_R, metrics_df_AB, save_path=None):\n",
    "    error_metrics = ['RMSE', 'MAE', 'MSE', 'ME']\n",
    "    aggregation_levels = ['30T', '1H', '1D']\n",
    "    aggregation_levels_str = ['30 min', '1 hour', '1 day']\n",
    "    \n",
    "    num_rows = len(aggregation_levels) + 1  # +1 for the non-aggregated metrics\n",
    "    num_cols = len(error_metrics)\n",
    "    \n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(35, 20))\n",
    "    \n",
    "    colors = {\n",
    "        'MP': 'orangered',\n",
    "        'MP_opt': 'green',\n",
    "        'R': 'blue',\n",
    "        'AB': 'purple'\n",
    "    }\n",
    "    labels = {\n",
    "        'MP': 'M0: Standard Parameters',\n",
    "        'MP_opt': 'M1: Optimized Parameters',\n",
    "        'R': 'M3: Image-to-point PINN (R)',\n",
    "        'AB': 'M3: Image-to-point PINN (AB)'\n",
    "    }\n",
    "    \n",
    "    for col, metric in enumerate(error_metrics):\n",
    "        # Top row: non-aggregated metrics\n",
    "        ax = axs[0, col]\n",
    "        positions = np.arange(len(metrics_df_MP['StationId']))\n",
    "        width = 0.2  # Width of the bars\n",
    "        ax.bar(positions - 1.5 * width, metrics_df_MP[metric], width, label=labels['MP'], color=colors['MP'], alpha=0.7)\n",
    "        ax.bar(positions - 0.5 * width, metrics_df_MP_opt[metric], width, label=labels['MP_opt'], color=colors['MP_opt'], alpha=0.7)\n",
    "        ax.bar(positions + 0.5 * width, metrics_df_R[metric], width, label=labels['R'], color=colors['R'], alpha=0.7)\n",
    "        #ax.bar(positions + 1.5 * width, metrics_df_AB[metric], width, label=labels['AB'], color=colors['AB'], alpha=0.7)\n",
    "        ax.set_title(f'{metric}', size=18)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        if col == 0:\n",
    "            ax.set_ylabel('5 min', fontsize=18)\n",
    "\n",
    "        # Subsequent rows: aggregated metrics\n",
    "        for row, interval in enumerate(aggregation_levels, start=1):\n",
    "            ax = axs[row, col]\n",
    "            interval_col = f'{metric}_{interval}'\n",
    "            ax.bar(positions - 1.5 * width, metrics_df_MP[interval_col], width, label=labels['MP'], color=colors['MP'], alpha=0.7)\n",
    "            ax.bar(positions - 0.5 * width, metrics_df_MP_opt[interval_col], width, label=labels['MP_opt'], color=colors['MP_opt'], alpha=0.7)\n",
    "            ax.bar(positions + 0.5 * width, metrics_df_R[interval_col], width, label=labels['R'], color=colors['R'], alpha=0.7)\n",
    "            #ax.bar(positions + 1.5 * width, metrics_df_AB[interval_col], width, label=labels['AB'], color=colors['AB'], alpha=0.7)\n",
    "            \n",
    "            if row == 0:\n",
    "                ax.set_title(f'{metric}', fontsize=14)\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f'{aggregation_levels_str[row-1]}', fontsize=18)\n",
    "            if row == num_rows - 1:\n",
    "                ax.set_xticks(positions)\n",
    "                ax.set_xticklabels(metrics_df_MP['StationId'], rotation=45, fontsize=16)\n",
    "            else:\n",
    "                ax.set_xticks([])\n",
    "                ax.set_xticklabels([])\n",
    "\n",
    "    # Create a single legend for the entire figure\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.99), ncol=2, fontsize=18, prop={'size': 18})\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)  # Adjust the top to make space for the legend\n",
    "    \n",
    "    if save_path:        \n",
    "        save_path = f'{save_path}_error_aggregated.png'\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0.01, dpi=300)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# metricsMP = calculate_metrics(df_test, 'MP')\n",
    "# metricsMP_opt = calculate_metrics(df_test, 'MP_opt')\n",
    "# metricsR = calculate_metrics(df_test, 'R_pred_R')\n",
    "# metricsAB = calculate_metrics(df_test, 'R_pred_AB')\n",
    "\n",
    "plot_error_metrics(metricsMP, metricsMP_opt, metricsR, metricsAB, save_path='path_to_save')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map plot of A, B and R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZR_test_dataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # It's assumed all these columns are numerical\n",
    "        self.X = df[['radar_norm', 'dist_coast', 'dist_radar', 'topo', 'toy_sin', 'toy_cos', 'tod_sin', 'tod_cos']].values\n",
    "        self.R = df['R'].values\n",
    "        self.Z = df['Z'].values\n",
    "        self.dBZ = df['dBZ'].values\n",
    "        \n",
    "        # Convert to PyTorch tensors once\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float)\n",
    "        self.R = torch.tensor(self.R, dtype=torch.float)\n",
    "        self.Z = torch.tensor(self.Z, dtype=torch.float)\n",
    "        self.dBZ = torch.tensor(self.dBZ, dtype=torch.float)\n",
    "\n",
    "        # Additional data like StationId and timestamp can be handled similarly if needed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.R)  # Assuming all columns have the same length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Directly index the pre-converted tensors\n",
    "        return {'R': self.R[idx], 'Z': self.Z[idx], 'dBZ': self.dBZ[idx], 'x': self.X[idx]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_dataset = ZR_test_dataset(csv_file='test_spatial.csv')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "logAs = []  \n",
    "Bs = []\n",
    "logR_preds = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for batch in tqdm(test_dataloader):\n",
    "        features = batch['x'].to(device)\n",
    "\n",
    "        # Make predictions\n",
    "        logA, B, x = model(features)\n",
    "\n",
    "        # Collect predictions\n",
    "        logAs.append(logA)\n",
    "        Bs.append(B)\n",
    "        logR_preds.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "df_test = pd.read_csv('test_spatial.csv')\n",
    "\n",
    "# Convert to appropriate types or calculate fields for entire DataFrame\n",
    "df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
    "df_test['year'] = df_test['timestamp'].dt.year\n",
    "df_test['month'] = df_test['timestamp'].dt.month\n",
    "\n",
    "# Apply calculations only for valid rows\n",
    "df_test[['MP', 'MP_opt', 'R_pred_R', 'R_pred_AB']] = 0.0\n",
    "df_test['MP'] = np.array(pf.dbz_to_R_marshall_palmer(df_test['dBZ'], 200, 1.6)).astype(float)\n",
    "df_test['MP_opt'] = np.array(pf.dbz_to_R_marshall_palmer(df_test['dBZ'], 186, 3.8)).astype(float)\n",
    "df_test['A'] = np.exp(torch.cat(logAs).cpu().numpy())\n",
    "df_test['B'] = torch.cat(Bs).cpu().numpy()\n",
    "df_test['R_pred_R'] = np.exp(torch.cat(logR_preds).cpu().numpy())\n",
    "df_test['R_pred_AB'] = np.array(pf.dbz_to_R_marshall_palmer(df_test['dBZ'], df_test['A'], df_test['B']))\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('df_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the matrix with NaNs instead of zeros to avoid a second pass for replacement\n",
    "R_pred_R = np.full((1728, 1984), np.nan)\n",
    "R_pred_AB = np.full((1728, 1984), np.nan)\n",
    "A_pred = np.full((1728, 1984), np.nan)\n",
    "B_pred = np.full((1728, 1984), np.nan)\n",
    "dBZ = np.full((1728, 1984), np.nan)\n",
    "\n",
    "# Extract row and column indices and R_pred_R values\n",
    "rows = df_test['row'].astype(int).values\n",
    "cols = df_test['col'].astype(int).values\n",
    "R_pred_values = df_test['R_pred_R'].values\n",
    "R_pred_AB_values = df_test['R_pred_AB'].values\n",
    "A_values = df_test['A'].values\n",
    "B_values = df_test['B'].values\n",
    "dBZ_values = df_test['dBZ'].values\n",
    "\n",
    "# Use numpy advanced indexing to assign values directly\n",
    "R_pred_R[rows, cols] = R_pred_values\n",
    "R_pred_AB[rows, cols] = R_pred_AB_values\n",
    "A_pred[rows, cols] = A_values\n",
    "B_pred[rows, cols] = B_values\n",
    "dBZ[rows, cols] = dBZ_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pf)\n",
    "from matplotlib import colors  \n",
    "\n",
    "# Define your rain rate boundaries\n",
    "rain_boundaries = [0.001, .5, 1, 2, 3, 4, 5, 7.5, 10, 15, 20]\n",
    "  \n",
    "cmap = colors.ListedColormap([\"#85E3E4\", '#42D8D8', '#42AFD8', '#4282D8', \"#FFE600\", '#FFAF00', '#FF5050', '#FF1A1A', \"#BD0000\", \"#8C0000\"])\n",
    "boundaries = np.round(rain_boundaries)\n",
    "norm = colors.BoundaryNorm(boundaries, cmap.N, clip=True)\n",
    "\n",
    "save_path = param_string + 'NN_R_rain_map' + '.png'\n",
    "pf.rain_map(R_pred_R, 'Rain Intensity', cmap = cmap, norm = norm, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = param_string + 'NN_AB_rain_map'  + '.png'\n",
    "pf.rain_map(R_pred_AB, 'Rain Intensity', cmap = cmap, norm = norm, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def read_rgb_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read all lines in the file\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Skip lines that do not contain color information\n",
    "    color_lines = [line for line in lines if line.strip() and not line.startswith('#') and not line.startswith('ncolors')]\n",
    "    \n",
    "    # Extract the RGB values\n",
    "    rgb_values = [tuple(map(int, line.strip().split()[:3])) for line in color_lines]\n",
    "    \n",
    "    # Normalize the RGB values to the range [0, 1]\n",
    "    rgb_normalized = [(r/255.0, g/255.0, b/255.0) for r, g, b in rgb_values]\n",
    "    \n",
    "    # Create a colormap from the RGB values\n",
    "    colormap = LinearSegmentedColormap.from_list(\"custom_radar\", rgb_normalized)\n",
    "    \n",
    "    return colormap\n",
    "\n",
    "# Use the function to create the colormap\n",
    "custom_colormap = read_rgb_file('radar.rgb')\n",
    "boundaries = np.linspace(0, 75, 16)\n",
    "norm = BoundaryNorm(boundaries, ncolors=custom_colormap.N, clip=True)\n",
    "\n",
    "save_path = param_string + 'dBZ_rain_map' +  '.png'\n",
    "pf.rain_map(dBZ, 'dBZ', cmap = custom_colormap , norm = norm, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = param_string + 'A_map' + '.png'\n",
    "pf.rain_map(A_pred, 'A', cmap = 'turbo', norm = None, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path =  param_string +'B_map'  + '.png'\n",
    "pf.rain_map(B_pred, 'B', cmap = 'turbo', norm = None, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),  param_string + 'model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
